
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

# data_science_bowl_2019

> The notebooks for the competition Data Science Bowl 2019



I join this competition
[data-science-bowl-2019](https://www.kaggle.com/c/data-science-bowl-2019),
which ends on January 15, 2020. For the data feature, I do some work on
the series features, using word2vec, LDA and node2vec.

1.  [wide and
    deep](https://github.com/JiaxiangBU/data-science-bowl-2019EX/blob/master/wide_and_deep.ipynb)
2.  [node2vec](https://github.com/JiaxiangBU/data-science-bowl-2019EX/blob/master/node2vec.ipynb)
3.  [LDA](https://github.com/JiaxiangBU/data-science-bowl-2019EX/blob/master/lda.ipynb)

The baseline feature engineering I forked from Hosseinali (2019).
However, it helps me focus on series features. Also, I use LTSM model to
elaborate series features, I forked from Grecnik (2019).

<div id="refs" class="references">

<div id="ref-Grecnik2019">

Grecnik. 2019. ¡°Bowl Lstm Prediction | Kaggle.¡± Kaggle. 2019.
<https://www.kaggle.com/nikitagrec/bowl-lstm-prediction>.

</div>

<div id="ref-Massoud_Hosseinali2019">

Hosseinali, Massoud. 2019. ¡°A New Baseline for Dsb 2019 - Catboost
Model.¡± Kaggle. 2019.
<https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model>.

</div>

</div>


## Install

`pip install data_science_bowl_2019`

## How to use

See demo.
