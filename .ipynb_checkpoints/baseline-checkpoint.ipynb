{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "> The baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I had posted my very naive baseline at https://www.kaggle.com/mhviraf/a-baseline-for-dsb-2019. In that kernel I only used the mode label for each Assessment and I thought it should be very easy to beat. This kernel shows how you can beat that baseline by actually applying a model. In this kernel via `get_data()` function, I go over each `installation_id` and try to extract some features based on his/her behavior prior to the assessment. I will then train a `Catboost` classifier on it and make predictions on the test set. Note that the features I made in this kernel are so very basic and you can easily add many more to it. Good luck and happy kaggling. Don't forget to upvote if you found it useful ;)\n",
    "\n",
    "This notebook is forked from https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from catboost import CatBoostClassifier\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def qwk(act,pred,n=4,hist_range=(0,3)):\n",
    "    \n",
    "    O = confusion_matrix(act,pred)\n",
    "    O = np.divide(O,np.sum(O))\n",
    "    \n",
    "    W = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            W[i][j] = ((i-j)**2)/((n-1)**2)\n",
    "            \n",
    "    act_hist = np.histogram(act,bins=n,range=hist_range)[0]\n",
    "    prd_hist = np.histogram(pred,bins=n,range=hist_range)[0]\n",
    "    \n",
    "    E = np.outer(act_hist,prd_hist)\n",
    "    E = np.divide(E,np.sum(E))\n",
    "    \n",
    "    num = np.sum(np.multiply(W,O))\n",
    "    den = np.sum(np.multiply(W,E))\n",
    "        \n",
    "    return 1-np.divide(num,den)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/'train.csv')\n",
    "train_labels = pd.read_csv(data_path/'train_labels.csv')\n",
    "specs = pd.read_csv(data_path/'specs.csv')\n",
    "test = pd.read_csv(data_path/'test.csv')\n",
    "submission = pd.read_csv(data_path/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode title\n",
    "list_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\n",
    "activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "\n",
    "train['title'] = train['title'].map(activities_map)\n",
    "test['title'] = test['title'].map(activities_map)\n",
    "train_labels['title'] = train_labels['title'].map(activities_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "win_code[activities_map['Bird Measurer (Assessment)']] = 4110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_data(user_sample, test_set=False):\n",
    "    last_activity = 0\n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy=0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0 \n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    durations = []\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        if test_set == True:\n",
    "            second_condition = True\n",
    "        else:\n",
    "            if len(session)>1:\n",
    "                second_condition = True\n",
    "            else:\n",
    "                second_condition= False\n",
    "            \n",
    "        if (session_type == 'Assessment') & (second_condition):\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            features = user_activities_count.copy()\n",
    "            features['session_title'] = session['title'].iloc[0] \n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "\n",
    "            features.update(accuracy_groups)\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            if test_set == True:\n",
    "                all_assessments.append(features)\n",
    "            else:\n",
    "                if true_attempts+false_attempts > 0:\n",
    "                    all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "\n",
    "    if test_set:\n",
    "        return all_assessments[-1] \n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\install\\miniconda\\lib\\site-packages\\ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d25297082de4c2f9c239621a240b453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Time-consuming block.\n",
    "compiled_data = []\n",
    "for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=17000):\n",
    "    compiled_data += get_data(user_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.DataFrame(compiled_data)\n",
    "del compiled_data\n",
    "new_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Below are the features I have generated. Note that all of them are **prior** to each event. For example, the first row shows **before** this assessment, the player have watched 3 clips, did 3 activities, played 4 games and solved 0 assessments, so on so forth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, just 16 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\n",
    "cat_features = ['session_title'] # 整个 Catboost 算法只考虑了这一个分类变量，有更多可以挖掘的。\n",
    "X, y = new_train[all_features], new_train['accuracy_group']\n",
    "# del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def make_classifier():\n",
    "    clf = CatBoostClassifier(\n",
    "                               loss_function='MultiClass',\n",
    "                               task_type=\"CPU\",\n",
    "                               learning_rate=0.01,\n",
    "                               iterations=2000,\n",
    "                               od_type=\"Iter\",\n",
    "                               early_stopping_rounds=500,\n",
    "                               random_seed=2019\n",
    "                              )\n",
    "        \n",
    "    return clf\n",
    "# 这个函数很 trivial，但是一共被调用了两次，所以函数化。\n",
    "oof = np.zeros(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV\n",
    "from sklearn.model_selection import KFold\n",
    "# preds = np.zeros(len(X_test))\n",
    "oof = np.zeros(len(X))\n",
    "NFOLDS = 5\n",
    "folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=2019)\n",
    "\n",
    "training_start_time = time()\n",
    "for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "    start_time = time()\n",
    "    print(f'Training on fold {fold+1}')\n",
    "    clf = make_classifier()\n",
    "    clf.fit(X.loc[trn_idx, all_features], y.loc[trn_idx], eval_set=(X.loc[test_idx, all_features], y.loc[test_idx]),\n",
    "                          use_best_model=True, verbose=500, cat_features=cat_features)\n",
    "    \n",
    "#     preds += clf.predict(X_test).reshape(len(X_test))/NFOLDS\n",
    "    oof[test_idx] = clf.predict(X.loc[test_idx, all_features]).reshape(len(test_idx))\n",
    "    \n",
    "    print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    \n",
    "print('-' * 30)\n",
    "print('OOF QWK:', qwk(y, oof))\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Cross validation is only for the feature engineering part and you don't actually need it if you want to submit the results. You can safely comment it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on all data once\n",
    "clf = make_classifier()\n",
    "clf.fit(X, y, verbose=500, cat_features=cat_features)\n",
    "\n",
    "# del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-consuming block\n",
    "# process test set\n",
    "new_test = []\n",
    "for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=1000):\n",
    "    a = get_data(user_sample, test_set=True)\n",
    "    new_test.append(a)\n",
    "    \n",
    "X_test = pd.DataFrame(new_test)\n",
    "# del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set once\n",
    "preds = clf.predict(X_test)\n",
    "# del X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['accuracy_group'] = np.round(preds).astype('int')\n",
    "submission.to_csv('output/submission_reproduction.csv', index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['accuracy_group'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['accuracy_group'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(oof).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save intermediate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(\"output/train_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
