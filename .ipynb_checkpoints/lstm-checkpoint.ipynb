{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model\n",
    "\n",
    "> run a RMM format model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fork this notebook from https://www.kaggle.com/nikitagrec/bowl-lstm-prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import warnings\n",
    "import random\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "my_pal = sns.color_palette(n_colors=10)\n",
    "\n",
    "from pathlib import Path\n",
    "data_path = Path('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11341042 #number of records in file\n",
    "s = 2000000 #desired sample size\n",
    "skip = sorted(random.sample(range(n),n-s)) # 这一步没有必要吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path/'train.csv', skiprows=skip)\n",
    "# Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
    "#     at the start of the file.\n",
    "train.columns = ['event_id','game_session','timestamp','event_data',\n",
    "            'installation_id','event_count','event_code','game_time','title','type','world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_path/'test.csv')\n",
    "labels = pd.read_csv(data_path/'train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(data_path/\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000, 11) (1156414, 11) (17690, 7)\n",
      "17690是训练集的size\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, labels.shape)\n",
    "print(str(labels.shape[0]) + '是训练集的size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['event_id', 'game_session', 'timestamp', 'event_data',\n",
      "       'installation_id', 'event_count', 'event_code', 'game_time', 'title',\n",
      "       'type', 'world'],\n",
      "      dtype='object')\n",
      "Index(['game_session', 'installation_id', 'title', 'num_correct',\n",
      "       'num_incorrect', 'accuracy', 'accuracy_group'],\n",
      "      dtype='object')\n",
      "Index(['event_id', 'game_session', 'timestamp', 'event_data',\n",
      "       'installation_id', 'event_count', 'event_code', 'game_time', 'title',\n",
      "       'type', 'world'],\n",
      "      dtype='object')\n",
      "Index(['installation_id', 'accuracy_group'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(labels.columns)\n",
    "print(test.columns)\n",
    "print(sample_submission.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from more_itertools import sliced\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = train.merge(labels, how='right', on=['installation_id','game_session']) # 一对多匹配\n",
    "train_ls = full[['installation_id','game_session','event_id']] # 只提取\n",
    "# convert to str\n",
    "train_ls['event_id'] = train_ls['event_id'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def events_all(aa):\n",
    "    xx = ''\n",
    "    for i in aa: \n",
    "        xx += i + ' '\n",
    "    xx = xx.rstrip()\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train_ls.groupby(['installation_id','game_session']).sum().reset_index()\n",
    "result['event_id'] = result['event_id'].apply(lambda x: list(sliced(x, 8)))\n",
    "result['new_event'] = result['event_id'].apply(events_all)\n",
    "result = result.merge(labels, how='right', on=['installation_id','game_session'])[['new_event','accuracy_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_event</th>\n",
       "      <th>accuracy_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1e4395d 7da34a02 fbaf3456 fbaf3456</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1375ccb7 e37a2b78 4a4c3d21 a16a373e e37a2b78 4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3bfd1a65 28ed704e c74f40cd c7128948 7da34a02 f...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3bfd1a65 a1e4395d 9d29771f 28ed704e a1e4395d a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a4c3d21 8fee50e2 8fee50e2 f6947f54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           new_event  accuracy_group\n",
       "0                a1e4395d 7da34a02 fbaf3456 fbaf3456               3\n",
       "1  1375ccb7 e37a2b78 4a4c3d21 a16a373e e37a2b78 4...               0\n",
       "2  3bfd1a65 28ed704e c74f40cd c7128948 7da34a02 f...               3\n",
       "3  3bfd1a65 a1e4395d 9d29771f 28ed704e a1e4395d a...               2\n",
       "4                4a4c3d21 8fee50e2 8fee50e2 f6947f54               3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head() # event 是一个序列特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17690, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['new_event']].to_csv(\"output/event_features.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 100\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(result['new_event'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (17690, 500)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(result['new_event'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (17690, 4)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(result['accuracy_group']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15921, 500) (15921, 4)\n",
      "(1769, 500) (1769, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14328 samples, validate on 1593 samples\n",
      "Epoch 1/5\n",
      "  896/14328 [>.............................] - ETA: 1:53 - loss: 1.3001 - accuracy: 0.4922"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# choose epochs and batch_size\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_train,Y_train)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没有过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_test = test[['installation_id','game_session',\n",
    "                  'timestamp']].groupby(['installation_id']).tail(1)[['installation_id','game_session']]\n",
    "test_ = test.merge(last_test,how='inner', on=['installation_id','game_session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ls = test_[['installation_id','game_session','event_id']]\n",
    "# test_ls = test[['installation_id','game_session','event_id']]\n",
    "test_ls['event_id'] = test_ls['event_id'].apply(lambda x: str(x))\n",
    "res_test = test_ls.groupby(['installation_id','game_session']).sum().reset_index()\n",
    "res_test['event_id'] = res_test['event_id'].apply(lambda x: list(sliced(x, 8)))\n",
    "res_test['new_event'] = res_test['event_id'].apply(events_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ts = tokenizer.texts_to_sequences(res_test['new_event'].values)\n",
    "X_ts = pad_sequences(X_ts, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([res_test['installation_id'],\n",
    "                                     pd.DataFrame(test_pred).idxmax(1)], axis=1)\n",
    "submission.columns = ['installation_id','accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission['accuracy_group'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/keras-ltsm-1.0.1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"output/embedding-train-x\", X)\n",
    "np.save(\"output/embedding-train-y\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
